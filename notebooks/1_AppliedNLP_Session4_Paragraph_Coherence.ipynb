{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f51338e",
   "metadata": {},
   "source": [
    "# Session 4 â€” Paragraph-Level Analysis\n",
    "## Measure 1: Paragraph Semantic Coherence\n",
    "\n",
    "In this notebook, you will:\n",
    "- split your text into paragraphs and sentences\n",
    "- compute **embedding-based coherence** per paragraph using MiniLM\n",
    "- compare coherence distributions across two books\n",
    "- connect this to how RAG systems and LLMs assess chunk quality\n",
    "\n",
    "We again use Lewis Carroll's *Alice* books as examples. Replace the file\n",
    "paths with your own author/text for your project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f38c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may need to install this once in your environment:\n",
    "# !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def load_book(filepath: str) -> str:\n",
    "    \"\"\"Load and lightly clean a book text (Project Gutenberg style).\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Very simple Project Gutenberg cleaner (adapt to your own corpus)\n",
    "    if 'CHAPTER I' in text:\n",
    "        start = text.find('CHAPTER I')\n",
    "        text = text[start:]\n",
    "    elif '*** START OF' in text:\n",
    "        start = text.find('*** START OF')\n",
    "        text = text[start + 100:]\n",
    "\n",
    "    if '*** END OF' in text:\n",
    "        end = text.find('*** END OF')\n",
    "        text = text[:end]\n",
    "    elif 'End of Project Gutenberg' in text:\n",
    "        end = text.find('End of Project Gutenberg')\n",
    "        text = text[:end]\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# Load both Alice books (replace with your own paths)\n",
    "wonderland_text = load_book('../data/Wonderland.txt')\n",
    "looking_glass_text = load_book('../data/Looking-Glass.txt')\n",
    "\n",
    "print(f\"Wonderland characters: {len(wonderland_text):,}\")\n",
    "print(f\"Looking-Glass characters: {len(looking_glass_text):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d85c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paragraphs(text: str, min_words: int = 10) -> List[str]:\n",
    "    \"\"\"Split raw text into paragraphs using blank lines as boundaries.\n",
    "    Filters out very short paragraphs (e.g. chapter titles).\"\"\"\n",
    "    text = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    raw_paras = re.split(r'\\n\\s*\\n+', text)\n",
    "    paras = []\n",
    "    for p in raw_paras:\n",
    "        cleaned = re.sub(r'\\s+', ' ', p).strip()\n",
    "        if not cleaned:\n",
    "            continue\n",
    "        if len(cleaned.split()) < min_words:\n",
    "            continue\n",
    "        paras.append(cleaned)\n",
    "    return paras\n",
    "\n",
    "def sentence_split(paragraph: str) -> List[str]:\n",
    "    \"\"\"Very simple sentence splitter based on punctuation.\"\"\"\n",
    "    sentences = re.split(r'[.!?]+\\s+', paragraph.strip())\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    return sentences\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    if a.ndim > 1:\n",
    "        a = a.reshape(-1)\n",
    "    if b.ndim > 1:\n",
    "        b = b.reshape(-1)\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "def paragraph_coherence_embeddings(paragraphs: List[str]) -> Tuple[list, list]:\n",
    "    \"\"\"Compute embedding-based coherence for each paragraph.\n",
    "\n",
    "    Steps:\n",
    "    - Split each paragraph into sentences\n",
    "    - Compute MiniLM embeddings for all sentences\n",
    "    - Compute the centroid (mean embedding) for the paragraph\n",
    "    - Coherence = average cosine similarity of each sentence\n",
    "      to the centroid embedding\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    lengths = []\n",
    "    for p in paragraphs:\n",
    "        sents = sentence_split(p)\n",
    "        if len(sents) < 2:\n",
    "            continue\n",
    "        # Encode all sentences in this paragraph\n",
    "        sent_embs = model.encode(sents)\n",
    "        centroid = sent_embs.mean(axis=0)\n",
    "        sims = [cosine_similarity(e, centroid) for e in sent_embs]\n",
    "        scores.append(sum(sims) / len(sims))\n",
    "        lengths.append(len(\" \".join(sents).split()))\n",
    "    return scores, lengths\n",
    "\n",
    "wonderland_paras = split_into_paragraphs(wonderland_text)\n",
    "looking_glass_paras = split_into_paragraphs(looking_glass_text)\n",
    "\n",
    "w_scores, w_lengths = paragraph_coherence_embeddings(wonderland_paras)\n",
    "g_scores, g_lengths = paragraph_coherence_embeddings(looking_glass_paras)\n",
    "\n",
    "print(f\"Wonderland mean coherence (embeddings): {sum(w_scores)/len(w_scores):.3f}\")\n",
    "print(f\"Looking-Glass mean coherence (embeddings): {sum(g_scores)/len(g_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coherence vs paragraph length\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "axes[0].scatter(w_lengths, w_scores, alpha=0.5)\n",
    "axes[0].set_title(\"Wonderland: coherence vs length (MiniLM)\")\n",
    "axes[0].set_xlabel(\"Paragraph length (tokens)\")\n",
    "axes[0].set_ylabel(\"Coherence (cosine)\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].scatter(g_lengths, g_scores, alpha=0.5)\n",
    "axes[1].set_title(\"Looking-Glass: coherence vs length (MiniLM)\")\n",
    "axes[1].set_xlabel(\"Paragraph length (tokens)\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions with histograms\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.hist(w_scores, bins=20, alpha=0.6, label='Wonderland', density=True)\n",
    "ax.hist(g_scores, bins=20, alpha=0.6, label='Looking-Glass', density=True)\n",
    "ax.set_xlabel('Paragraph coherence (cosine similarity to centroid)')\n",
    "ax.set_ylabel('Density (normalized)')\n",
    "ax.set_title('Distribution of Paragraph Coherence (MiniLM embeddings)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad499e10",
   "metadata": {},
   "source": [
    "## Memory Cleanup\n",
    "\n",
    "If you're running low on memory, run this cell to free up RAM by deleting large variables and clearing the model cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Delete large variables to free memory\n",
    "del wonderland_text, looking_glass_text\n",
    "del wonderland_paras, looking_glass_paras\n",
    "del w_scores, w_lengths, g_scores, g_lengths\n",
    "\n",
    "# Clear matplotlib figures\n",
    "plt.close('all')\n",
    "\n",
    "# Unload the model from memory\n",
    "del model\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "print(\"Memory cleaned! Large variables deleted and garbage collected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
