{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d7c454",
   "metadata": {},
   "source": [
    "# Session 4 â€” Paragraph-Level Analysis\n",
    "## Measure 2: Topic Drift Between Paragraphs\n",
    "\n",
    "In this notebook, you will:\n",
    "- represent each paragraph as a MiniLM embedding\n",
    "- compute cosine similarity between consecutive paragraphs\n",
    "- interpret low similarity as strong topic/scene shifts\n",
    "- connect this to how LLM systems segment long documents\n",
    "  into chunks for retrieval and long-context reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ffc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may need to install this once in your environment:\n",
    "# !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def load_book(filepath: str) -> str:\n",
    "    \"\"\"Load and lightly clean a book text (Project Gutenberg style).\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    if 'CHAPTER I' in text:\n",
    "        start = text.find('CHAPTER I')\n",
    "        text = text[start:]\n",
    "    elif '*** START OF' in text:\n",
    "        start = text.find('*** START OF')\n",
    "        text = text[start + 100:]\n",
    "\n",
    "    if '*** END OF' in text:\n",
    "        end = text.find('*** END OF')\n",
    "        text = text[:end]\n",
    "    elif 'End of Project Gutenberg' in text:\n",
    "        end = text.find('End of Project Gutenberg')\n",
    "        text = text[:end]\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "wonderland_text = load_book('../data/Wonderland.txt')\n",
    "looking_glass_text = load_book('../data/Looking-Glass.txt')\n",
    "\n",
    "print(f\"Wonderland characters: {len(wonderland_text):,}\")\n",
    "print(f\"Looking-Glass characters: {len(looking_glass_text):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89073030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paragraphs(text: str, min_words: int = 10) -> List[str]:\n",
    "    text = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    raw_paras = re.split(r'\\n\\s*\\n+', text)\n",
    "    paras = []\n",
    "    for p in raw_paras:\n",
    "        cleaned = re.sub(r'\\s+', ' ', p).strip()\n",
    "        if not cleaned:\n",
    "            continue\n",
    "        if len(cleaned.split()) < min_words:\n",
    "            continue\n",
    "        paras.append(cleaned)\n",
    "    return paras\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    if a.ndim > 1:\n",
    "        a = a.reshape(-1)\n",
    "    if b.ndim > 1:\n",
    "        b = b.reshape(-1)\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "def topic_drift_embeddings(paragraphs: List[str]) -> list:\n",
    "    \"\"\"Compute cosine similarity between consecutive paragraph embeddings.\n",
    "\n",
    "    Low similarity = big topic shift (high drift).\n",
    "    High similarity = smooth continuation.\n",
    "    \"\"\"\n",
    "    if not paragraphs:\n",
    "        return []\n",
    "    para_embs = model.encode(paragraphs)\n",
    "    sims = []\n",
    "    for i in range(len(para_embs) - 1):\n",
    "        sims.append(cosine_similarity(para_embs[i], para_embs[i+1]))\n",
    "    return sims\n",
    "\n",
    "wonderland_paras = split_into_paragraphs(wonderland_text)\n",
    "looking_glass_paras = split_into_paragraphs(looking_glass_text)\n",
    "\n",
    "w_drift = topic_drift_embeddings(wonderland_paras)\n",
    "g_drift = topic_drift_embeddings(looking_glass_paras)\n",
    "\n",
    "print(f\"Wonderland mean similarity between consecutive paragraphs: {sum(w_drift)/len(w_drift):.3f}\")\n",
    "print(f\"Looking-Glass mean similarity between consecutive paragraphs: {sum(g_drift)/len(g_drift):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622bc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topic drift as a line plot (similarity index)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=False)\n",
    "\n",
    "axes[0].plot(w_drift, alpha=0.8)\n",
    "axes[0].set_title('Wonderland: similarity between consecutive paragraphs (MiniLM)')\n",
    "axes[0].set_ylabel('Cosine similarity')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(g_drift, alpha=0.8)\n",
    "axes[1].set_title('Looking-Glass: similarity between consecutive paragraphs (MiniLM)')\n",
    "axes[1].set_xlabel('Paragraph index')\n",
    "axes[1].set_ylabel('Cosine similarity')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.hist(w_drift, bins=20, alpha=0.6, label='Wonderland', density=True)\n",
    "ax.hist(g_drift, bins=20, alpha=0.6, label='Looking-Glass', density=True)\n",
    "ax.set_xlabel('Cosine similarity between consecutive paragraphs (MiniLM)')\n",
    "ax.set_ylabel('Density (normalized)')\n",
    "ax.set_title('Distribution of Topic Continuity (higher = smoother transitions)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c134ed",
   "metadata": {},
   "source": [
    "## Memory Cleanup\n",
    "\n",
    "If you're running low on memory, run this cell to free up RAM by deleting large variables and clearing the model cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Delete large variables to free memory\n",
    "del wonderland_text, looking_glass_text\n",
    "del wonderland_paras, looking_glass_paras\n",
    "del w_drift, g_drift\n",
    "\n",
    "# Clear matplotlib figures\n",
    "plt.close('all')\n",
    "\n",
    "# Unload the model from memory\n",
    "del model\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "print(\"Memory cleaned! Large variables deleted and garbage collected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
